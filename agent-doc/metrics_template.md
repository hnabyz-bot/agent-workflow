# AI Agent 워크플로우 효율성 측정 템플릿

## 1. 목적

이 문서는 AI Agent 협업 워크플로우의 실제 효과를 **정량적으로 측정**하기 위한 템플릿입니다.
파일럿 프로젝트 시작 전, 이 템플릿을 복사하여 프로젝트 진행 중 데이터를 기록하고, 종료 후 분석하여 워크플로우의 ROI를 검증합니다.

## 2. 측정 대상 프로젝트 정보

| 항목 | 내용 |
|------|------|
| **프로젝트명** | [예: URL Shortener API] |
| **팀 규모** | [예: 3인] |
| **프로젝트 기간** | YYYY-MM-DD ~ YYYY-MM-DD |
| **코드베이스 규모** | [예: 신규 프로젝트 / 기존 5,000 LOC] |
| **도메인** | [예: Web API / 데이터 파이프라인 / 임베디드] |

## 3. 핵심 측정 지표 (KPI)

### 3.1 시간 효율성 측정

#### A. 전체 개발 시간
- **예상 소요 시간 (워크플로우 미적용 시):** ______ 시간
- **실제 소요 시간 (워크플로우 적용 시):** ______ 시간
- **시간 절감률:** ______ %

#### B. Agent 전환 오버헤드 측정
**기록 방법:** 매 Agent 전환 시 아래 표에 기록

| 전환 시각 | From | To | 전환 사유 | 준비 시간 (분) | 비고 |
|----------|------|-----|----------|---------------|------|
| 01-10 10:30 | Claude | Gemini | 아키텍처 검토 | 12 | project_status.md 업데이트 + 계획서 복사 |
| 01-10 14:15 | Gemini | Copilot | 구현 시작 | 8 | 설계 의사코드 전달 |
| ... | ... | ... | ... | ... | ... |

**분석:**
- **총 전환 횟수:** ______ 회
- **평균 전환 시간:** ______ 분
- **총 오버헤드 시간:** ______ 시간
- **전체 개발 시간 대비 오버헤드 비율:** ______ %
- **목표 대비 평가:** (목표: 25% 이하)

### 3.2 품질 측정

#### A. 결함 밀도 (Defect Density)
**측정 시점:** 프로젝트 종료 후 1주일 내 발견된 버그

- **총 코드 라인 수 (LOC):** ______
- **발견된 결함 수:** ______
- **결함 밀도 (결함 수 / KLOC):** ______
- **비교 기준:** [팀 평균 또는 과거 프로젝트: ______]

#### B. 테스트 커버리지
- **단위 테스트 커버리지:** ______ %
- **통합 테스트 커버리지:** ______ %
- **목표 대비 달성률:** ______ %

#### C. 코드 복잡도
**도구:** `radon`, `pylint`, `eslint` 등 사용

- **평균 Cyclomatic Complexity:** ______
- **고복잡도 함수 (CC > 10) 비율:** ______ %

#### D. 품질 게이트 실패율
- **총 품질 게이트 검증 횟수:** ______ 회
- **실패 횟수:** ______ 회
- **실패율:** ______ %

### 3.3 Agent별 기여도 분석

| Agent | 총 작업 시간 (시간) | 주요 산출물 | 재작업 횟수 | 품질 게이트 통과율 (%) |
|-------|-------------------|------------|------------|---------------------|
| Claude | | | | |
| Gemini | | | | |
| Copilot | | | | |

**분석:**
- **재작업이 가장 많았던 Agent:** ______
- **가장 효율적이었던 Agent:** ______

## 4. 워크플로우 준수도 평가

### 4.1 핵심 원칙 준수 체크리스트

| 원칙 | 준수율 (%) | 미준수 사례 수 | 주요 미준수 사유 |
|------|-----------|--------------|----------------|
| `project_status.md` 매 핸드오프마다 업데이트 | | | |
| 품질 게이트 체크리스트 사용 | | | |
| 순차 활용 우선 (불필요한 전환 최소화) | | | |
| 핸드오프 프로토콜 준수 | | | |

### 4.2 실패 복구 프로토콜 사용 통계

| 실패 유형 | 발생 횟수 | 평균 복구 시간 (분) | 비고 |
|----------|----------|-------------------|------|
| Agent 출력 검증 실패 | | | |
| 핸드오프 컨텍스트 손실 | | | |
| 연쇄 실패 (Cascading Failure) | | | |

## 5. 정성적 평가

### 5.1 팀원 만족도 설문 (5점 척도)

| 질문 | 점수 (1-5) | 비고 |
|------|-----------|------|
| 워크플로우가 생산성을 높였는가? | | |
| Agent 역할 분장이 명확했는가? | | |
| `project_status.md`가 도움이 되었는가? | | |
| 품질 게이트가 품질 향상에 기여했는가? | | |
| 다음 프로젝트에서도 사용하고 싶은가? | | |

### 5.2 가장 큰 장점 3가지
1.
2.
3.

### 5.3 가장 큰 개선점 3가지
1.
2.
3.

## 6. ROI 최종 분석

### 6.1 효율성 증가 검증
```
시간 절감 = (예상 시간 - 실제 시간) / 예상 시간 × 100
목표: 40-50% (README.md 기준)
실제: ______ %
```

### 6.2 품질 개선 검증
```
품질 개선 = (팀 평균 결함 밀도 - 이번 프로젝트 결함 밀도) / 팀 평균 결함 밀도 × 100
목표: 15-20% (agent_consensus_analysis.md 기준)
실제: ______ %
```

### 6.3 오버헤드 비용 평가
```
순수익 = 절감된 시간 - 오버헤드 시간
ROI = 순수익 / 오버헤드 시간 × 100
실제: ______ %
```

## 7. 최종 권장사항

### 7.1 이 워크플로우를 계속 사용해야 하는가?
- [ ] **예** - ROI가 양수이며, 팀 만족도가 높음
- [ ] **조건부 예** - 일부 개선 후 재시도
- [ ] **아니오** - ROI가 음수이거나, 오버헤드가 과도함

### 7.2 다음 프로젝트 적용 시 변경할 사항
1.
2.
3.

### 7.3 확장 적용 가능 범위
- [ ] 유사한 규모/도메인 프로젝트
- [ ] 더 큰 규모 프로젝트
- [ ] 다른 도메인
- [ ] 전사 확대
- [ ] 적용 불가

---

**작성일:** YYYY-MM-DD
**작성자:** [이름]
**검토자:** [이름]
